{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb0ebaf1",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-2/trim-filter-messages.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239435-lesson-4-trim-and-filter-messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52ea2f9-03ff-4647-b782-46867ebed04e",
   "metadata": {},
   "source": [
    "# Filtering and trimming messages\n",
    "\n",
    "## Review\n",
    "\n",
    "Now, we have a deeper understanding of a few things: \n",
    "\n",
    "* How to customize the graph state schema\n",
    "* How to define custom state reducers\n",
    "* How to use multiple graph state schemas\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, we can start using these concepts with models in LangGraph!\n",
    " \n",
    "In the next few sessions, we'll build towards a chatbot that has long-term memory.\n",
    "\n",
    "Because our chatbot will use messages, let's first talk a bit more about advanced ways to work with messages in graph state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5197aba-5d46-421b-ae3b-4e3034edcfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_core langgraph langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "768dc606-d5f2-468d-96ea-910b264e0f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# This function reads the variables from your .env file\n",
    "# and loads them into the environment for your script to use.\n",
    "load_dotenv()\n",
    "\n",
    "# Now you can securely access your API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    print(\"API key not found. Please check your .env file.\")\n",
    "else:\n",
    "    print(\"OpenAI API key loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b64d8d3-e4ac-4961-bdc0-688825eb5864",
   "metadata": {},
   "source": [
    "We'll use [LangSmith](https://docs.smith.langchain.com/) for [tracing](https://docs.smith.langchain.com/concepts/tracing).\n",
    "\n",
    "We'll log to a project, `langchain-academy`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd020c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load variables from your .env file\n",
    "load_dotenv()\n",
    "\n",
    "# These lines ensure tracing is enabled for the correct project\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langsmith-academy\"\n",
    "\n",
    "print(\"Environment variables loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f3fc90-58b6-4f7f-897e-dddf6ae532c7",
   "metadata": {},
   "source": [
    "## Messages as state\n",
    "\n",
    "First, let's define some messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf11a463-e27a-4a05-b41d-64882e38edca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Bot\n",
      "\n",
      "So you said you were researching ocean mammals?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "Yes, I know about whales. But what others should I learn about?\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "messages = [AIMessage(f\"So you said you were researching ocean mammals?\", name=\"Bot\")]\n",
    "messages.append(HumanMessage(f\"Yes, I know about whales. But what others should I learn about?\", name=\"Lance\"))\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b814adcb-6bf9-4b75-be11-e59f933fbd0c",
   "metadata": {},
   "source": [
    "Recall we can pass them to a chat model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4712e288-e622-48a2-ad3f-a52f65f3ab08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='In addition to whales, there are several fascinating ocean mammals worth learning about. Here are a few:\\n\\n1. **Dolphins**: These intelligent and social creatures are known for their playful behavior and are found in oceans worldwide. There are many species, such as the bottlenose dolphin and the orca or killer whale, which is technically a dolphin.\\n\\n2. **Porpoises**: Similar to dolphins but generally smaller and with different facial features, porpoises are also toothed whales and are found in both coastal and offshore waters.\\n\\n3. **Seals**: These include different species, such as the harbor seal and the elephant seal. They are part of the pinniped group, which also includes sea lions and walruses.\\n\\n4. **Sea Lions**: Known for their external ear flaps and loud barks, sea lions are more social than seals and are often found in coastal areas.\\n\\n5. **Walruses**: Recognizable by their large tusks, walruses are important inhabitants of Arctic regions, feeding primarily on benthic invertebrates.\\n\\n6. **Manatees**: Sometimes called \"sea cows,\" manatees are gentle herbivores found in warm coastal waters and rivers. They\\'re related to the dugong in the Indo-Pacific region.\\n\\n7. **Dugongs**: Similar to manatees but with a fluked tail like a whale, dugongs inhabit coastal and marine areas from East Africa to Australia.\\n\\n8. **Otters**: While not exclusively marine, species like the sea otter live predominantly in ocean environments, playing a critical role in maintaining the health of kelp forests.\\n\\nEach of these ocean mammals has unique characteristics and ecological roles, making them fascinating subjects for study.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 355, 'prompt_tokens': 39, 'total_tokens': 394, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CS2r4gYbeWRMC4SBoib824HCyUS3q', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--19daad3f-d055-46ea-8ca7-92d0dfd2b5d6-0', usage_metadata={'input_tokens': 39, 'output_tokens': 355, 'total_tokens': 394, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd1dab8-0af8-4621-8264-ce65065f76ec",
   "metadata": {},
   "source": [
    "We can run our chat model in a simple graph with `MessagesState`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd8c39c-633b-4176-9cc6-8318e42bb5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Node\n",
    "def chat_model_node(state: MessagesState):\n",
    "    return {\"messages\": llm.invoke(state[\"messages\"])}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"chat_model\", chat_model_node)\n",
    "builder.add_edge(START, \"chat_model\")\n",
    "builder.add_edge(\"chat_model\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5a3e4a-ccfd-4d14-81f1-f0de6e11a1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = graph.invoke({'messages': messages})\n",
    "for m in output['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c33e63-1ef4-412d-bb10-6a1b9e5b35a7",
   "metadata": {},
   "source": [
    "## Reducer\n",
    "\n",
    "A practical challenge when working with messages is managing long-running conversations. \n",
    "\n",
    "Long-running conversations result in high token usage and latency if we are not careful, because we pass a growing list of messages to the model.\n",
    "\n",
    "We have a few ways to address this.\n",
    "\n",
    "First, recall the trick we saw using `RemoveMessage` and the `add_messages` reducer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222c6bc5-bb0e-4a43-80f5-c8ec38d99f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import RemoveMessage\n",
    "\n",
    "# Nodes\n",
    "def filter_messages(state: MessagesState):\n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"messages\": delete_messages}\n",
    "\n",
    "def chat_model_node(state: MessagesState):    \n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"filter\", filter_messages)\n",
    "builder.add_node(\"chat_model\", chat_model_node)\n",
    "builder.add_edge(START, \"filter\")\n",
    "builder.add_edge(\"filter\", \"chat_model\")\n",
    "builder.add_edge(\"chat_model\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a7c2cc-54ce-43e7-9a90-abf37827d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message list with a preamble\n",
    "messages = [AIMessage(\"Hi.\", name=\"Bot\", id=\"1\")]\n",
    "messages.append(HumanMessage(\"Hi.\", name=\"Lance\", id=\"2\"))\n",
    "messages.append(AIMessage(\"So you said you were researching ocean mammals?\", name=\"Bot\", id=\"3\"))\n",
    "messages.append(HumanMessage(\"Yes, I know about whales. But what others should I learn about?\", name=\"Lance\", id=\"4\"))\n",
    "\n",
    "# Invoke\n",
    "output = graph.invoke({'messages': messages})\n",
    "for m in output['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f506457d-014b-4fee-a684-e5edfb4b8f0d",
   "metadata": {},
   "source": [
    "## Filtering messages\n",
    "\n",
    "If you don't need or want to modify the graph state, you can just filter the messages you pass to the chat model.\n",
    "\n",
    "For example, just pass in a filtered list: `llm.invoke(messages[-1:])` to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d0b904-7cd6-486b-8948-105bee3d4683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node\n",
    "def chat_model_node(state: MessagesState):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"][-1:])]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"chat_model\", chat_model_node)\n",
    "builder.add_edge(START, \"chat_model\")\n",
    "builder.add_edge(\"chat_model\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f58c6fc-532f-418d-b70a-cfcb3307daf5",
   "metadata": {},
   "source": [
    "Let's take our existing list of messages, append the above LLM response, and append a follow-up question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16956015-1dbe-4108-89b5-4209b68b51ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(output['messages'][-1])\n",
    "messages.append(HumanMessage(f\"Tell me more about Narwhals!\", name=\"Lance\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85563415-c085-46a8-a4ac-155df798c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23349705-a059-47b5-9760-d8f64e687393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke, using message filtering\n",
    "output = graph.invoke({'messages': messages})\n",
    "for m in output['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e1d8d2-e297-4d78-b54c-d12b3c866745",
   "metadata": {},
   "source": [
    "The state has all of the mesages.\n",
    "\n",
    "But, let's look at the LangSmith trace to see that the model invocation only uses the last message:\n",
    "\n",
    "https://smith.langchain.com/public/75aca3ce-ef19-4b92-94be-0178c7a660d9/r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc40d930-3c1f-47fe-8d2a-ce174873353c",
   "metadata": {},
   "source": [
    "## Trim messages\n",
    "\n",
    "Another approach is to [trim messages](https://python.langchain.com/v0.2/docs/how_to/trim_messages/#getting-the-last-max_tokens-tokens), based upon a set number of tokens. \n",
    "\n",
    "This restricts the message history to a specified number of tokens.\n",
    "\n",
    "While filtering only returns a post-hoc subset of the messages between agents, trimming restricts the number of tokens that a chat model can use to respond.\n",
    "\n",
    "See the `trim_messages` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff99b81-cf03-4cc2-b44f-44829a73e1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import trim_messages\n",
    "\n",
    "# Node\n",
    "def chat_model_node(state: MessagesState):\n",
    "    messages = trim_messages(\n",
    "            state[\"messages\"],\n",
    "            max_tokens=100,\n",
    "            strategy=\"last\",\n",
    "            token_counter=ChatOpenAI(model=\"gpt-4o\"),\n",
    "            allow_partial=False,\n",
    "        )\n",
    "    return {\"messages\": [llm.invoke(messages)]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"chat_model\", chat_model_node)\n",
    "builder.add_edge(START, \"chat_model\")\n",
    "builder.add_edge(\"chat_model\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24df63ac-da29-4874-b3df-7e390e97cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(output['messages'][-1])\n",
    "messages.append(HumanMessage(f\"Tell me where Orcas live!\", name=\"Lance\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9d8971-c75c-43ca-a209-eb1d07b2ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of trimming messages\n",
    "trim_messages(\n",
    "            messages,\n",
    "            max_tokens=100,\n",
    "            strategy=\"last\",\n",
    "            token_counter=ChatOpenAI(model=\"gpt-4o\"),\n",
    "            allow_partial=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed70a269-a869-4fa0-a1df-29736a432c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke, using message trimming in the chat_model_node \n",
    "messages_out_trim = graph.invoke({'messages': messages})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b3db67-380e-46b5-9a6a-20100ba52008",
   "metadata": {},
   "source": [
    "Let's look at the LangSmith trace to see the model invocation:\n",
    "\n",
    "https://smith.langchain.com/public/b153f7e9-f1a5-4d60-8074-f0d7ab5b42ef/r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy-env (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d161c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- First Run ---\n",
      "[HumanMessage(content=\"Hi! I'm Bob.\", additional_kwargs={}, response_metadata={}), AIMessage(content='Hello Bob! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 12, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CTpSUBeDJDfdIfAwEFcDdJ9dwsK38', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--a76e8b70-9e26-4c50-98c9-6438b118c849-0', usage_metadata={'input_tokens': 12, 'output_tokens': 10, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\n",
      "--- Second Run ---\n",
      "[HumanMessage(content=\"Hi! I'm Bob.\", additional_kwargs={}, response_metadata={}), AIMessage(content='Hello Bob! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 12, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CTpSUBeDJDfdIfAwEFcDdJ9dwsK38', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--a76e8b70-9e26-4c50-98c9-6438b118c849-0', usage_metadata={'input_tokens': 12, 'output_tokens': 10, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Hello Bob! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 26, 'total_tokens': 36, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a788c5aef0', 'id': 'chatcmpl-CTpSWB1dN6cnkjq6Dltry7dnC7rAX', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--5491f757-8b38-426a-a55d-c2b339462735-0', usage_metadata={'input_tokens': 26, 'output_tokens': 10, 'total_tokens': 36, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load API keys and set up tracing\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"Intro to LangGraph\"\n",
    "\n",
    "# --- Define the State Schema with a Reducer ---\n",
    "# By using Annotated and operator.add, we're telling the graph\n",
    "# that any new 'messages' should be added to the existing list,\n",
    "# not replace it. This is a \"reducer\".\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n",
    "# --- Define Nodes ---\n",
    "def call_llm(state: GraphState):\n",
    "    # This node just calls the LLM with the current list of messages\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "    response = llm.invoke(state['messages'])\n",
    "    # The new message is returned, and the reducer will add it to the state\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# --- Build the Graph ---\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Add the single node\n",
    "workflow.add_node(\"llm\", call_llm)\n",
    "\n",
    "# Set the entry point and exit point\n",
    "workflow.set_entry_point(\"llm\")\n",
    "workflow.add_edge(\"llm\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "# --- Run the Graph ---\n",
    "# We'll run it twice to show how the state is accumulated\n",
    "\n",
    "print(\"--- First Run ---\")\n",
    "# The initial input is a list with one message\n",
    "initial_state = {\"messages\": [HumanMessage(content=\"Hi! I'm Bob.\")]}\n",
    "final_state_1 = app.invoke(initial_state)\n",
    "print(final_state_1['messages'])\n",
    "\n",
    "print(\"\\n--- Second Run ---\")\n",
    "# For the second run, we pass the final state from the first run.\n",
    "# The reducer will add the new messages to this existing list.\n",
    "final_state_2 = app.invoke(final_state_1)\n",
    "print(final_state_2['messages'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy-env (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3056216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Retrieving Documents ---\n",
      "--- retriever ---\n",
      "{'documents': ['The James Webb Space Telescope is the most powerful space telescope, using infrared light to observe distant objects, with a 6.5m mirror, and', 'As the largest telescope in space, it is equipped with high-resolution and high-sensitivity instruments, allowing it to view objects too old, distant, or faint', 'The James Webb Space Telescope is the most advanced telescope, focusing on infrared, can see distant galaxies, and can see back to the beginning of the']}\n",
      "--- Generating Answer ---\n",
      "--- generator ---\n",
      "{'answer': 'The key features of the James Webb Space Telescope include its ability to use infrared light to observe distant objects, its large 6.5-meter mirror, and its high-resolution and high-sensitivity instruments. These features allow it to view objects that are too old, distant, or faint, and to see back to the beginning of the universe.'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, List\n",
    "\n",
    "# âœ… Correct imports for latest LangGraph version\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from tavily import TavilyClient\n",
    "\n",
    "# Load API keys and set up tracing\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"Intro to LangGraph\"\n",
    "\n",
    "# Define the data structure (state) that will flow through the graph\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    documents: List[str]\n",
    "    answer: str\n",
    "\n",
    "# Define the nodes for our graph\n",
    "def retrieve_documents(state: GraphState):\n",
    "    # This node gets documents from the web based on the question\n",
    "    print(\"--- Retrieving Documents ---\")\n",
    "    question = state.get('question', '')\n",
    "    tavily = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "    results = tavily.search(query=question, max_results=3)\n",
    "    documents = [res['content'] for res in results['results']]\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "def generate_answer(state: GraphState):\n",
    "    # This node generates an answer using the retrieved documents\n",
    "    print(\"--- Generating Answer ---\")\n",
    "    question = state.get('question', '')\n",
    "    documents = state.get('documents', [])\n",
    "    \n",
    "    prompt = f\"\"\"You are an assistant for question-answering tasks.\n",
    "    Use the following retrieved context to answer the question.\n",
    "    If you don't know the answer, just say that you don't know.\n",
    "    \n",
    "    Context: {documents}\n",
    "    Question: {question}\n",
    "    Answer:\"\"\"\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "# Build the graph\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Add the nodes\n",
    "workflow.add_node(\"retriever\", retrieve_documents)\n",
    "workflow.add_node(\"generator\", generate_answer)\n",
    "\n",
    "# Define the edges to connect the nodes in sequence\n",
    "workflow.add_edge(START, \"retriever\")\n",
    "workflow.add_edge(\"retriever\", \"generator\")\n",
    "workflow.add_edge(\"generator\", END)\n",
    "\n",
    "# Compile the graph into a runnable application\n",
    "app = workflow.compile()\n",
    "\n",
    "# Run the graph and stream the results\n",
    "inputs = {\"question\": \"What are the key features of the James Webb Space Telescope?\"}\n",
    "for event in app.stream(inputs):\n",
    "    for key, value in event.items():\n",
    "        print(f\"--- {key} ---\")\n",
    "        print(value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy-env (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

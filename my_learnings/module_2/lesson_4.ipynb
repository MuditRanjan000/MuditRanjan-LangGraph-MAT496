{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae306b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running graph with trimmed message history ---\n",
      "\n",
      "--- Final AI Response ---\n",
      "Building a custom agent can be a rewarding project, and the tools you use will depend on the specific tasks you want the agent to perform. Here are some options and approaches you might consider:\n",
      "\n",
      "1. **Programming Languages**:\n",
      "   - **Python**: Known for its simplicity and vast array of libraries, Python is ideal for building agents, especially those that involve data processing, machine learning, or automation.\n",
      "   - **JavaScript (Node.js)**: Ideal for real-time applications and web-based agents.\n",
      "   - **Java**: Good for enterprise-level applications where performance and scalability are crucial.\n",
      "\n",
      "2. **Frameworks and Libraries**:\n",
      "   - **Dialogflow**: Useful for building conversational agents. It's backed by Google and offers integrations with various platforms.\n",
      "   - **Rasa**: An open-source Python framework for building AI assistants that give you full control over your machine learning models and data.\n",
      "   - **IBM Watson Assistant**: Provides tools to build, train, and deploy conversational interactions into any application or device.\n",
      "   - **Microsoft Bot Framework**: A comprehensive framework for building chatbots that can integrate with various platforms.\n",
      "\n",
      "3. **Machine Learning**:\n",
      "   - **TensorFlow or PyTorch**: If you’re building an agent that involves deep learning, these frameworks can be very powerful.\n",
      "   - **scikit-learn**: For more traditional machine learning tasks and models.\n",
      "\n",
      "4. **APIs and Services**:\n",
      "   - **OpenAI’s API**: For advanced natural language processing tasks.\n",
      "   - **Amazon Lex**: Allows you to build conversational interfaces using voice and text.\n",
      "\n",
      "5. **Development Tools**:\n",
      "   - **VSCode or PyCharm**: Robust code editors that support various languages and extensions for AI development.\n",
      "   - **GitHub or GitLab**: For version control and collaboration.\n",
      "\n",
      "6. **Cloud Services**:\n",
      "   - **AWS, Google Cloud, Azure**: If you need scalability, deploying your agent on cloud platforms can offer benefits like load balancing and robust data handling.\n",
      "\n",
      "7. **Integration Tools**:\n",
      "   - **Zapier or Integromat/Make**: Useful for integrating your agent with other software services.\n",
      "\n",
      "The choice of tools will largely depend on your specific requirements, budget, and the scale of your project. If you provide more details about the type of agent you want to build, I could offer more tailored advice.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import Annotated, TypedDict\n",
    "import operator\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# Load API keys and set up tracing\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"Intro to LangGraph\"\n",
    "\n",
    "# Define the State Schema\n",
    "# 'add_messages' is a special helper that appends new messages to the list.\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# Define the Node\n",
    "def call_llm(state: GraphState):\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "    response = llm.invoke(state['messages'])\n",
    "    # The 'add_messages' reducer automatically appends this response\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Build the Graph\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"llm\", call_llm)\n",
    "workflow.add_edge(\"llm\", END)\n",
    "workflow.set_entry_point(\"llm\")\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "# --- Run the Graph with Message Trimming ---\n",
    "\n",
    "# Here's a long list of messages to simulate a conversation\n",
    "inputs = [\n",
    "    HumanMessage(content=\"Hi! I'm Bob.\"),\n",
    "    HumanMessage(content=\"I'm a builder.\"),\n",
    "    HumanMessage(content=\"I'm looking for a new tool.\"),\n",
    "    HumanMessage(content=\"I want to build a custom agent.\"),\n",
    "    HumanMessage(content=\"What should I use?\")\n",
    "]\n",
    "\n",
    "print(\"--- Running graph with trimmed message history ---\")\n",
    "\n",
    "# In the config, we can pass a function to transform the state for a specific node.\n",
    "# Here, we're telling the \"llm\" node to only use the last 2 messages.\n",
    "final_state = app.invoke({\"messages\": inputs}, config={\"llm\": {\"messages\": lambda x: x[-2:]}})\n",
    "\n",
    "print(\"\\n--- Final AI Response ---\")\n",
    "# The final answer is based only on the trimmed history\n",
    "print(final_state['messages'][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy-env (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

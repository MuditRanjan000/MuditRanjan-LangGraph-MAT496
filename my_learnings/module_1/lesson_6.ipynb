{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6d63e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Agent with a tool-calling question ---\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_VMvCRxAUxacA29DKlpwSdmYr', 'function': {'arguments': '{\"query\":\"San Francisco weather\"}', 'name': 'search_tavily'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 81, 'total_tokens': 99, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f64f290af2', 'id': 'chatcmpl-CRHG3twXhAzGDfN8KIIAiYODZomuR', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8ee33221-ec97-4adb-aa3a-d91a4d27ba8b-0', tool_calls=[{'name': 'search_tavily', 'args': {'query': 'San Francisco weather'}, 'id': 'call_VMvCRxAUxacA29DKlpwSdmYr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 81, 'output_tokens': 18, 'total_tokens': 99, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "{'messages': [ToolMessage(content='[{\\'title\\': \\'Weather in San Francisco, California, USA\\', \\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1760617427, \\'localtime\\': \\'2025-10-16 05:23\\'}, \\'current\\': {\\'last_updated_epoch\\': 1760616900, \\'last_updated\\': \\'2025-10-16 05:15\\', \\'temp_c\\': 9.4, \\'temp_f\\': 48.9, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Fog\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/248.png\\', \\'code\\': 1135}, \\'wind_mph\\': 3.8, \\'wind_kph\\': 6.1, \\'wind_degree\\': 352, \\'wind_dir\\': \\'N\\', \\'pressure_mb\\': 1019.0, \\'pressure_in\\': 30.09, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 97, \\'cloud\\': 25, \\'feelslike_c\\': 8.8, \\'feelslike_f\\': 47.8, \\'windchill_c\\': 10.9, \\'windchill_f\\': 51.6, \\'heatindex_c\\': 11.0, \\'heatindex_f\\': 51.7, \\'dewpoint_c\\': 7.0, \\'dewpoint_f\\': 44.5, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 0.0, \\'gust_mph\\': 5.9, \\'gust_kph\\': 9.4}}\", \\'score\\': 0.9563821, \\'raw_content\\': None}, {\\'url\\': \\'https://world-weather.info/forecast/usa/san_francisco/october-2025/\\', \\'title\\': \\'Weather in San Francisco in October 2025 (California)\\', \\'content\\': \\'*   [15 +63° +55° 4.5 mph S 30 inHg 75 %07:18 am 06:32 pm](https://world-weather.info/forecast/usa/san_francisco/14days/#2025-10-15) *   [16 +63° +54° 15.7 mph W 29.9 inHg 66 %07:19 am 06:30 pm](https://world-weather.info/forecast/usa/san_francisco/14days/#2025-10-16) *   [17 +68° +52° 10.7 mph W 29.9 inHg 57 %07:20 am 06:29 pm](https://world-weather.info/forecast/usa/san_francisco/14days/#2025-10-17) *   [20 +66° +54° 16.1 mph W 29.9 inHg 45 %07:23 am 06:25 pm](https://world-weather.info/forecast/usa/san_francisco/14days/#2025-10-20) *   [21 +66° +54° 15 mph W 29.9 inHg 43 %07:24 am 06:23 pm](https://world-weather.info/forecast/usa/san_francisco/14days/#2025-10-21) *   [22 +64° +54° 13.4 mph W 30 inHg 59 %07:25 am 06:22 pm](https://world-weather.info/forecast/usa/san_francisco/14days/#2025-10-22) *   [23 +64° +52° 2.2 mph S 30 inHg 86 %07:26 am 06:21 pm](https://world-weather.info/forecast/usa/san_francisco/14days/#2025-10-23) *   [24 +64° +52° 6.5 mph W 29.9 inHg 71 %07:27 am 06:20 pm](https://world-weather.info/forecast/usa/san_francisco/14days/#2025-10-24) *   [25 +61° +55° 14.1 mph W 30.1 inHg 84 %07:28 am 06:18 pm](https://world-weather.info/forecast/usa/san_francisco/14days/#2025-10-25)\\', \\'score\\': 0.9437689, \\'raw_content\\': None}]', tool_call_id='call_VMvCRxAUxacA29DKlpwSdmYr')]}\n",
      "{'messages': [AIMessage(content='The current weather in San Francisco is foggy, with a temperature of 9.4°C (48.9°F). It is relatively humid, with humidity at 97%, and the visibility is 16 km (9 miles). The wind is blowing from the north at a speed of 3.8 mph (6.1 kph).', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 1132, 'total_tokens': 1203, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f64f290af2', 'id': 'chatcmpl-CRHG9nZdQCdrV6CQuLrTqAoJFVcTJ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--84ed54ea-155a-4b27-a2aa-37e7d60f0b00-0', usage_metadata={'input_tokens': 1132, 'output_tokens': 71, 'total_tokens': 1203, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "\n",
      "--- Running Agent with a direct question ---\n",
      "{'messages': [AIMessage(content='2 + 2 equals 4.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 81, 'total_tokens': 90, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f64f290af2', 'id': 'chatcmpl-CRHGBtCLnf6THhMilZVmh8ovR80D3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--866c7904-2bda-433e-ba8b-6700eae69995-0', usage_metadata={'input_tokens': 81, 'output_tokens': 9, 'total_tokens': 90, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "from tavily import TavilyClient\n",
    "\n",
    "# Load API keys and set up tracing\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"Intro to LangGraph\"\n",
    "\n",
    "# --- Define Tools ---\n",
    "# This time, we'll give our agent two tools to choose from.\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def search_tavily(query: str) -> str:\n",
    "    \"\"\"Searches the web for the user's query using the Tavily API.\"\"\"\n",
    "    tavily = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "    results = tavily.search(query=query, max_results=2)\n",
    "    return str(results['results'])\n",
    "\n",
    "tools = [multiply, search_tavily]\n",
    "\n",
    "# --- Define State and Nodes ---\n",
    "# The state will now just be a list of messages to keep track of the conversation.\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n",
    "def call_llm(state: GraphState):\n",
    "    # The primary node that calls the LLM. It can either generate a\n",
    "    # direct response or decide to call one or more tools.\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "    messages = state['messages']\n",
    "    \n",
    "    # We bind our tools to the LLM so it knows about them.\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    \n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def call_tool(state: GraphState):\n",
    "    # This node executes the tools that the LLM decided to call.\n",
    "    last_message = state['messages'][-1]\n",
    "    tool_messages = []\n",
    "    \n",
    "    # Loop through all the tool calls in the last message\n",
    "    for tool_call in last_message.tool_calls:\n",
    "        tool_name = tool_call['name']\n",
    "        tool_args = tool_call['args']\n",
    "        \n",
    "        # Find the correct tool to call\n",
    "        if tool_name == \"multiply\":\n",
    "            result = multiply.invoke(tool_args)\n",
    "        elif tool_name == \"search_tavily\":\n",
    "            result = search_tavily.invoke(tool_args)\n",
    "        \n",
    "        # Append the tool's result to our list of messages\n",
    "        tool_messages.append(ToolMessage(content=str(result), tool_call_id=tool_call['id']))\n",
    "        \n",
    "    return {\"messages\": tool_messages}\n",
    "\n",
    "# --- Define the Router (Conditional Edge) ---\n",
    "def should_call_tool(state: GraphState):\n",
    "    # Our router checks the last message to see if it contains tool calls.\n",
    "    last_message = state['messages'][-1]\n",
    "    if last_message.tool_calls:\n",
    "        # If it does, we route to the 'call_tool' node.\n",
    "        return \"call_tool\"\n",
    "    # Otherwise, the graph can end.\n",
    "    return END\n",
    "\n",
    "# --- Build the Graph ---\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Add the nodes\n",
    "workflow.add_node(\"llm\", call_llm)\n",
    "workflow.add_node(\"call_tool\", call_tool)\n",
    "\n",
    "# The entry point is the 'llm' node.\n",
    "workflow.set_entry_point(\"llm\")\n",
    "\n",
    "# Add the conditional edge for routing\n",
    "workflow.add_conditional_edges(\n",
    "    \"llm\",\n",
    "    should_call_tool,\n",
    ")\n",
    "\n",
    "# After calling a tool, we always loop back to the LLM\n",
    "workflow.add_edge(\"call_tool\", \"llm\")\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "# --- Run the Agent ---\n",
    "print(\"--- Running Agent with a tool-calling question ---\")\n",
    "# This input should trigger the 'search_tavily' tool.\n",
    "tool_input = {\"messages\": [(\"user\", \"What's the weather like in San Francisco?\")]}\n",
    "for event in app.stream(tool_input):\n",
    "    for value in event.values():\n",
    "        print(value)\n",
    "\n",
    "print(\"\\n--- Running Agent with a direct question ---\")\n",
    "# This input should be answered directly by the LLM without using a tool.\n",
    "direct_input = {\"messages\": [(\"user\", \"What is 2 + 2?\")]}\n",
    "for event in app.stream(direct_input):\n",
    "    for value in event.values():\n",
    "        print(value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eef29d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph is a framework designed for creating sophisticated language model applications. It leverages the power of directed acyclic graphs (DAGs) to build and structure workflows that can execute various tasks, typically involving iterative and conditional processes. At its core, LangGraph focuses on enhancing the flexibility and modularity of language models by allowing developers to define and manage complex sequences of operations within a graph-like architecture.\n",
      "\n",
      "This approach enables easier management of dependencies, parallel execution of tasks, and a more intuitive way to trace and debug workflows as compared to linear or monolithic script structures. LangGraph is particularly valuable for applications that require complex interactions between different datasets or models, offering a structured way to manage the flow of information and model responses.\n",
      "\n",
      "If youâ€™re planning to develop advanced language processing applications, LangGraph could streamline the process by providing a clear framework for managing multifaceted interactions, reducing redundancy, and enhancing both scalability and maintainability of the codebase.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load your API keys from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set up LangSmith tracing for this project\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"Intro to LangGraph\"\n",
    "\n",
    "# Define the state of our graph\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        input: The user's input string.\n",
    "        output: The LLM's generated response.\n",
    "    \"\"\"\n",
    "    input: str\n",
    "    output: str\n",
    "\n",
    "# Define the node that will call the LLM\n",
    "def call_llm(state: GraphState):\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "    user_input = state['input']\n",
    "    response = llm.invoke(user_input)\n",
    "    # Update the state with the model's output\n",
    "    return {\"output\": response.content}\n",
    "\n",
    "# Build the graph\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"llm\", call_llm)\n",
    "workflow.add_edge(START, \"llm\")\n",
    "workflow.add_edge(\"llm\", END)\n",
    "\n",
    "# Compile the graph into a runnable object\n",
    "app = workflow.compile()\n",
    "\n",
    "# Run the graph and print the final output\n",
    "final_state = app.invoke({\"input\": \"What is LangGraph?\"})\n",
    "print(final_state['output'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2fb25fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langgraph.checkpoint.sqlite'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AIMessage, ToolMessage\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprebuilt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ToolNode\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcheckpoint\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msqlite\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SqliteSaver\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Load API keys and set up tracing\u001b[39;00m\n\u001b[32m     14\u001b[39m load_dotenv()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langgraph.checkpoint.sqlite'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "# Load API keys and set up tracing\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"Intro to LangGraph\"\n",
    "\n",
    "# --- Define Tools ---\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def search_tavily(query: str) -> str:\n",
    "    \"\"\"Searches the web for the user's query using the Tavily API.\"\"\"\n",
    "    from tavily import TavilyClient\n",
    "    tavily = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "    results = tavily.search(query=query, max_results=2)\n",
    "    return str(results['results'])\n",
    "\n",
    "tools = [multiply, search_tavily]\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# --- Define State ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n",
    "# --- Define Nodes and Router ---\n",
    "def call_llm(state: GraphState):\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "    messages = state['messages']\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_call_tool(state: GraphState):\n",
    "    last_message = state['messages'][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"call_tool\"\n",
    "    return END\n",
    "\n",
    "# --- Build the Graph ---\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"llm\", call_llm)\n",
    "workflow.add_node(\"call_tool\", tool_node)\n",
    "workflow.set_entry_point(\"llm\")\n",
    "workflow.add_conditional_edges(\"llm\", should_call_tool)\n",
    "workflow.add_edge(\"call_tool\", \"llm\")\n",
    "\n",
    "# --- Set up Memory ---\n",
    "# The checkpointer saves the state of the graph after each step\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "\n",
    "# Compile the graph with the checkpointer to enable memory\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "# --- Run the Agent ---\n",
    "# Use a config with a thread_id to identify the conversation\n",
    "config = {\"configurable\": {\"thread_id\": \"my-thread-1\"}}\n",
    "\n",
    "print(\"--- First turn ---\")\n",
    "for event in app.stream({\"messages\": [(\"user\", \"What's the weather in San Francisco?\")]}, config):\n",
    "    for v in event.values():\n",
    "        print(v)\n",
    "\n",
    "print(\"\\n--- Second turn ---\")\n",
    "# Ask a follow-up; the agent should remember the context\n",
    "for event in app.stream({\"messages\": [(\"user\", \"What about in Paris?\")]}, config):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
